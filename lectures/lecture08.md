### Lecture: 8. Continuous Action Space: DDPG, TD3, SAC
#### Date: Apr 09
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl139/2425/slides/?08
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl139/2425/slides.pdf/npfl139-2425-08.pdf,PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl139/2425/npfl139-2425-08.mp4, Lecture
#### Questions: #lecture_8_questions

- Gradient methods with continuous actions [Section 13.7 of RLB]
- Deterministic policy gradient theorem (DPG) [[David Silver et al.: Deterministic Policy Gradient Algorithms](http://proceedings.mlr.press/v32/silver14.pdf)]
- Deep deterministic policy gradient (DDPG) [[Timothy P. Lillicrap et al.: Continuous Control with Deep Reinforcement Learning](https://arxiv.org/abs/1509.02971)]
- Twin delayed deep deterministic policy gradient (TD3) [[Scott Fujimoto et al.: Addressing Function Approximation Error in Actor-Critic Methods](https://arxiv.org/abs/1802.09477)]
- Soft actor-critic (SAC) [[Tuomas Haarnoja et al.: Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/abs/1801.01290)]
