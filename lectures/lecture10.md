### Lecture: 10. PPO, R2D2, Agent57
#### Date: Apr 23
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl139/2425/slides/?10
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl139/2425/slides.pdf/npfl139-2425-10.pdf,PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl139/2425/npfl139-2425-10.mp4, Lecture
#### Questions: #lecture_10_questions
#### Lecture assignment: ppo

- _Natural policy gradient (NPG) [[Sham Kakade: A Natural Policy Gradient](https://papers.nips.cc/paper/2073-a-natural-policy-gradient.pdf)]_
- _Truncated natural policy gradient (TNPG), Trust Region Policy Optimalization (TRPO) [[John Schulman et al.: Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477)]_
- PPO algorithm [[John Schulman et al.: Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)]
- Transformed rewards [[Tobias Pohlen et al.: Observe and Look Further: Achieving Consistent Performance on Atari](https://arxiv.org/abs/1805.11593)]
- Recurrent Replay Distributed DQN (R2D2) [[Steven Kapturowski et al.: Recurrent Experience Replay in Distributed Reinforcement Learning](https://openreview.net/forum?id=r1lyTjAqYX)]
- Retrace [[Rémi Munos et al.:Safe and Efficient Off-Policy Reinforcement Learning](https://arxiv.org/abs/1606.02647)]
- _Never Give Up [[Adrià Puigdomènech Badia et al.: Never Give Up: Learning Directed Exploration Strategies](https://arxiv.org/abs/2002.06038)]]_
- _Agent57 [[Adrià Puigdomènech Badia et al.: Agent57: Outperforming the Atari Human Benchmark](https://arxiv.org/abs/2003.13350)]]_
